{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68072cc4-c1bd-44a2-836a-47dbbc61ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05aabfd-0a8b-4749-85cb-968eacbb673c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "259d1f23-fd99-46c5-86b0-bbe4f1e222bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3a3fd7-2224-4813-b0a2-c246b21a93df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baecfeff-92ea-478f-a7aa-ccb1c00c2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility fucntion we will use later when comparing manual vs PyTorch gradients\n",
    "\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa2e07cb-d799-4f34-9e81-3795b4cd4594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5) #* 0.2n ## read the paper from Kaiming\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.ones((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.zeros((1, n_hidden))*0.1\n",
    "\n",
    "\n",
    "#bnmean_running = torch.zeros((1, n_hidden))\n",
    "#bnstd_running = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8dbd7a-f136-497b-9014-fbbe4d3bac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "\n",
    "# contruct a minibatch\n",
    "\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator = g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a57b1ad0-aec5-426b-a89d-05bc124b2132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3396, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Forward Pass expanded into smaller steps\n",
    "\n",
    "emb = C[Xb] # embed the character into vectors\n",
    "embcat = emb.view(emb.shape[0] , -1) # concatenate the vectors\n",
    "\n",
    "# Liner layer 1\n",
    "\n",
    "hprebn = embcat @ W1 + b1 # hidden layer - pre activation\n",
    "\n",
    "# Batch Norm Layer\n",
    "\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bassel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-Linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "\n",
    "# Linear Layer 2\n",
    "\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # substrct max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1,keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1  # if I use (1.0/counts_sum) instead then I can't get backprop to be exact ...\n",
    "\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "          bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani, \n",
    "          embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f1befd8-5f5f-4010-9db4-cd0ee137a358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs  # check the derivate of log it d(logx/dx) = 1/x and due to chain rule multiply with dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum # dcounts was already calculated above so thatwhy we add +=\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "  for j in range(Xb.shape[1]):\n",
    "    ix = Xb[k,j]\n",
    "    dC[ix] += demb[k,j]\n",
    "    \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f27ebd7-0d36-4baf-a800-c5b4e95eaa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3396244049072266 diff: -2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f6300d4-f854-4a94-8c32-1211b8262c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 8.381903171539307e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dc8d41a-12ea-4477-b603-94d9a18c2b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c2aa01c-9e11-474c-bb49-b26fe882eceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0710, 0.0880, 0.0186, 0.0500, 0.0196, 0.0826, 0.0242, 0.0358, 0.0180,\n",
       "        0.0315, 0.0370, 0.0364, 0.0371, 0.0287, 0.0349, 0.0137, 0.0091, 0.0194,\n",
       "        0.0158, 0.0541, 0.0500, 0.0215, 0.0253, 0.0711, 0.0590, 0.0260, 0.0215],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b71c426c-0735-43a5-9512-22f045ecd3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0710,  0.0880,  0.0186,  0.0500,  0.0196,  0.0826,  0.0242,  0.0358,\n",
       "        -0.9820,  0.0315,  0.0370,  0.0364,  0.0371,  0.0287,  0.0349,  0.0137,\n",
       "         0.0091,  0.0194,  0.0158,  0.0541,  0.0500,  0.0215,  0.0253,  0.0711,\n",
       "         0.0590,  0.0260,  0.0215], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7c4209c-0c89-471f-9f96-8218ec1e8856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6566e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c30954db-bdcd-43a3-ad1e-1adab66f8037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x165ebc610>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee4d169f-2296-4ca2-aaef-c72af6a05c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "febd44e6-1cdb-4654-bd1c-6ac9125073a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2c88d-d72a-4e0b-9904-14a284584d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
